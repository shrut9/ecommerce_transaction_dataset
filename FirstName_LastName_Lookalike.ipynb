{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgp+KERao3ukF3PtvEdjaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrut9/ecommerce_transaction_dataset/blob/main/FirstName_LastName_Lookalike.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g69w2YyKv6Aj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import davies_bouldin_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv('/content/Customers.csv')\n",
        "products = pd.read_csv('/content/Products.csv')\n",
        "transactions = pd.read_csv('/content/Transactions.csv')"
      ],
      "metadata": {
        "id": "trsKpBeowT6u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge Data"
      ],
      "metadata": {
        "id": "M4o5HSBlxh-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = transactions.merge(customers, on='CustomerID', how='inner').merge(products, on='ProductID', how='inner')\n"
      ],
      "metadata": {
        "id": "D8dqljTrxksG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Price' not in merged_data.columns:\n",
        "    merged_data['Price'] = merged_data['TotalValue'] / merged_data['Quantity']"
      ],
      "metadata": {
        "id": "UMsYOFWfz57y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_data.columns)\n",
        "print(merged_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj-FRXO6z8uq",
        "outputId": "c99f9ace-c68f-463e-db5c-1c93b4a0977f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
            "       'Quantity', 'TotalValue', 'Price_x', 'CustomerName', 'Region',\n",
            "       'SignupDate', 'ProductName', 'Category', 'Price_y', 'Price'],\n",
            "      dtype='object')\n",
            "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
            "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
            "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
            "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
            "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
            "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
            "\n",
            "   TotalValue  Price_x     CustomerName         Region  SignupDate  \\\n",
            "0      300.68   300.68   Andrea Jenkins         Europe  2022-12-03   \n",
            "1      300.68   300.68  Brittany Harvey           Asia  2024-09-04   \n",
            "2      300.68   300.68  Kathryn Stevens         Europe  2024-04-04   \n",
            "3      601.36   300.68  Travis Campbell  South America  2024-04-11   \n",
            "4      902.04   300.68    Timothy Perez         Europe  2022-03-15   \n",
            "\n",
            "                       ProductName     Category  Price_y   Price  \n",
            "0  ComfortLiving Bluetooth Speaker  Electronics   300.68  300.68  \n",
            "1  ComfortLiving Bluetooth Speaker  Electronics   300.68  300.68  \n",
            "2  ComfortLiving Bluetooth Speaker  Electronics   300.68  300.68  \n",
            "3  ComfortLiving Bluetooth Speaker  Electronics   300.68  300.68  \n",
            "4  ComfortLiving Bluetooth Speaker  Electronics   300.68  300.68  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n"
      ],
      "metadata": {
        "id": "kqr56jvLxqi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate data for each customer\n",
        "customer_profiles = merged_data.groupby('CustomerID').agg({\n",
        "    'TotalValue': 'sum',       # Total spending\n",
        "    'Quantity': 'sum',         # Total quantity purchased\n",
        "    'Price': 'mean',           # Average price of purchased products\n",
        "    'Region': 'first',         # Region of the customer\n",
        "}).reset_index()"
      ],
      "metadata": {
        "id": "-2waMLRFxuWb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "Ls4OQTV40YAl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_features = customer_profiles.drop(['CustomerID'], axis=1)"
      ],
      "metadata": {
        "id": "3IOZenZR0fkj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Features for Similarity Computation\n",
        "scaler = StandardScaler()\n",
        "customer_features_scaled = scaler.fit_transform(customer_features)"
      ],
      "metadata": {
        "id": "bDrjOxiT0o0Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = cosine_similarity(customer_features_scaled)"
      ],
      "metadata": {
        "id": "YJgQ3SD70wv5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Recommendations for the First 20 Customers\n",
        "recommendations = {}\n",
        "customer_ids = customer_profiles['CustomerID'].tolist()\n",
        "\n",
        "for i in range(20):\n",
        "    customer_id = customer_ids[i]\n",
        "    similarity_scores = similarity_matrix[i]\n",
        "    similar_indices = similarity_scores.argsort()[-4:-1][::-1]\n",
        "    similar_customers = [(customer_ids[idx], similarity_scores[idx]) for idx in similar_indices]\n",
        "    recommendations[customer_id] = similar_customers"
      ],
      "metadata": {
        "id": "SHJbuSXz06Rn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Recommendations to CSV\n",
        "lookalike_df = pd.DataFrame.from_dict(recommendations, orient='index', columns=['Similar_Customer1', 'Similar_Customer2', 'Similar_Customer3'])\n",
        "lookalike_df = lookalike_df.reset_index().rename(columns={'index': 'CustomerID'})\n",
        "lookalike_df.to_csv('FirstName_LastName_Lookalike.csv', index=False)"
      ],
      "metadata": {
        "id": "oqIUPao21G9Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('FirstName_LastName_Lookalike.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vRhQidqY2D0u",
        "outputId": "6baf081e-4d49-4be9-cb50-27712175649b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7cfde69f-be1b-463c-8f6b-d33015f740a6\", \"FirstName_LastName_Lookalike.csv\", 2098)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer Similarity-based Recommendation Model\n",
        "This notebook will show how to build a customer similarity-based recommendation model using cosine similarity. The objective is to recommend customers who have similar purchasing behaviors, based on aggregated data from transactions. This involves data preprocessing, similarity calculation, and generation of recommendations.\n",
        "\n",
        "1. Importing Required Libraries\n",
        "\n",
        "We start by importing necessary libraries for handling data manipulation and machine learning tasks.\n",
        "\n",
        "Pandas is used for loading, merging, and processing data.\n",
        "\n",
        "sklearn.metrics.pairwise.cosine_similarity is used to calculate the similarity between customer profiles.\n",
        "\n",
        "sklearn.preprocessing.StandardScaler is used for feature scaling to make sure all variables have equal weight.\n",
        "\n",
        "google.colab.files is used to upload and download files in the Colab environment.\n",
        "\n",
        "2. Loading and Exploring the Data\n",
        "\n",
        "There are three input data CSV files used:\n",
        "Customers.csv contains information about the customers.\n",
        "Products.csv contains information about the products.\n",
        "Transactions.csv contains links of customers with the products based on their transactions.\n",
        "\n",
        "In Google Colab, these are uploaded using the files.upload() function. After uploading, we load data into pandas DataFrames and inspect the columns to ensure the structure is as expected.\n",
        "\n",
        "3. Merging Datasets\n",
        "We merge datasets using a merge() function based on common columns:\n",
        "\n",
        "CustomerID : This is a unique identifier for each customer.\n",
        "ProductID : This is a unique identifier for each product.\n",
        "\n",
        "This produces one DataFrame that provides all information related to each transaction, such as customer demographics, product information, and transaction data.\n",
        "\n",
        "Also, in case the Price column is absent, we calculate it by dividing TotalValue by Quantity, that is, unit price.\n",
        "\n",
        "4. Aggregating Customer Profiles\n",
        "\n",
        "We aggregate data for every customer by grouping it according to CustomerID. The aggregated metrics include:\n",
        "\n",
        "TotalValue: The total amount spent by the customer.\n",
        "Quantity: Total quantity of products purchased.\n",
        "\n",
        "Price: Mean price of the items bought.\n",
        "\n",
        "Region: The region the customer is from (this variable is categorical).\n",
        "\n",
        "To include Region in the similarity calculations, we use One-Hot Encoding to transform it into numeric features.\n",
        "\n",
        "5. Feature Scaling\n",
        "\n",
        "As the cosine similarity measure is sensitive to the magnitude of the data, we scale our features with StandardScaler so that each feature, such as Total spending, quantity, would influence the computation equally.\n",
        "\n",
        "6. Cosine Similarity Calculation\n",
        "\n",
        "We now calculate the cosine similarity matrix based on the standardized customer profiles. Cosine similarity is the measure of how similar two vectors are in relation to each other, by angle regardless of any scale the vectors might have. The smaller angle means higher similarity.\n",
        "\n",
        "To compute the similarity scores between all customers, we use the cosine_similarity() function from the sklearn package. This results in a matrix where each element represents the similarity score of a pair of customers.\n",
        "\n",
        "7. Generation of Recommendations\n",
        "\n",
        "For each customer, we identify the 3 most similar customers. It is done in the following steps:\n",
        "\n",
        "Fetch the similarity scores for a specific customer.\n",
        "\n",
        "Then sort the scores in descending order, and pick up the top three excluding the customer.\n",
        "\n",
        "These similar customers are recommended by their purchasing patterns.\n",
        "\n",
        "8. Save and Download the Recommendations\n",
        "\n",
        "The recommendations are saved in a new DataFrame, which contains each row as a customer with their top 3 most similar customers and similarity scores.\n",
        "\n",
        "Finally, we save this DataFrame to a CSV file called FirstName_LastName_Lookalike.csv. In Google Colab, we trigger the file download using files.download().\n",
        "\n",
        "9. Conclusion\n",
        "\n",
        "It will help a company to recommend a product to customers similar to the active one-a feature useful for targeted marketing, cross-selling opportunities, and increasing the customer experience level. The resulting recommendations are saved as a CSV file and can be downloaded for further analysis or integration into a larger system."
      ],
      "metadata": {
        "id": "U1ajd0Id3nsn"
      }
    }
  ]
}